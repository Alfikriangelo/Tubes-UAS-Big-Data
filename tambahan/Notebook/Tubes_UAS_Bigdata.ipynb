{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# pip install sqlalchemy psycopg2-binary pandas"
      ],
      "metadata": {
        "id": "wmRM4X7UIdiA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import sqlite3\n",
        "import os\n",
        "import time\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "1jxsRO2S_AUI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup**"
      ],
      "metadata": {
        "id": "ZT0ZmMEiIiYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "BASE_DIR = \"/content/drive/MyDrive/dataset/bigdata/uas\"\n",
        "RAW_DIR = f\"{BASE_DIR}/raw\"\n",
        "DB_PATH = f\"{BASE_DIR}/warehouse.db\"\n",
        "\n",
        "os.makedirs(RAW_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "6O8FSFYu_Bhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b9c329-a79c-4acc-b03d-42c5453b0a77"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXTRACT**"
      ],
      "metadata": {
        "id": "HwN1Eil6_MYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# EXTRACT\n",
        "# =========================================================\n",
        "def extract_etl_source1():\n",
        "    start = time.time()\n",
        "\n",
        "    path = f\"{BASE_DIR}/credit_card_transactions.csv\"\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    raw_path = f\"{RAW_DIR}/raw_credit_card.csv\"\n",
        "    df.to_csv(raw_path, index=False)\n",
        "\n",
        "    print(\"[EXTRACT] Credit Card Dataset\")\n",
        "    print(\"Rows:\", df.shape[0], \"Cols:\", df.shape[1])\n",
        "    print(\"Execution time:\", round(time.time() - start, 2), \"sec\\n\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def extract_etl_source2():\n",
        "    start = time.time()\n",
        "\n",
        "    url = \"https://api.stlouisfed.org/fred/series/observations\"\n",
        "    params = {\n",
        "        \"series_id\": \"FEDFUNDS\",\n",
        "        \"api_key\": \"51c9062a781c9b5719b643681e26d34b\",\n",
        "        \"file_type\": \"json\",\n",
        "        \"frequency\": \"m\"\n",
        "    }\n",
        "\n",
        "    resp = requests.get(url, params=params)\n",
        "    resp.raise_for_status()\n",
        "\n",
        "    data = resp.json()[\"observations\"]\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    raw_path = f\"{RAW_DIR}/raw_fred_fedfunds.csv\"\n",
        "    df.to_csv(raw_path, index=False)\n",
        "\n",
        "    print(\"[EXTRACT] FRED FEDFUNDS\")\n",
        "    print(\"Rows:\", df.shape[0], \"Cols:\", df.shape[1])\n",
        "    print(\"Execution time:\", round(time.time() - start, 2), \"sec\\n\")\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "UxVbPZVT_Eec"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRANSFORM**"
      ],
      "metadata": {
        "id": "LOenquKG_Ox7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = extract_etl_source1()\n",
        "df_fred = extract_etl_source2()"
      ],
      "metadata": {
        "id": "duzUlQeD_Qbj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d00001-21ed-4a59-935b-219cc240e912"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EXTRACT] Credit Card Dataset\n",
            "Rows: 1296675 Cols: 24\n",
            "Execution time: 38.37 sec\n",
            "\n",
            "[EXTRACT] FRED FEDFUNDS\n",
            "Rows: 858 Cols: 4\n",
            "Execution time: 0.26 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"===== TRANSFORM START =====\")\n",
        "print(\"Initial shape:\", df.shape, \"\\n\")"
      ],
      "metadata": {
        "id": "hP4ezvjz_buw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eb1da01-de32-441f-ab26-d613582a5afb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== TRANSFORM START =====\n",
            "Initial shape: (1296675, 24) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 1. STANDARDISASI NAMA KOLOM\n",
        "# ---------------------------------------------------------\n",
        "print(\"[CLEANING] Standardisasi Nama Kolom\")\n",
        "\n",
        "df.columns = (\n",
        "    df.columns\n",
        "    .str.strip()\n",
        "    .str.lower()\n",
        "    .str.replace(r\"[^\\w]+\", \"_\", regex=True)  # FIX: hapus ':' dll\n",
        ")\n",
        "\n",
        "# FIX: drop kolom index bawaan CSV\n",
        "if \"unnamed_0\" in df.columns:\n",
        "    df = df.drop(columns=[\"unnamed_0\"])\n",
        "\n",
        "print(\"Columns after standardization:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"-\" * 60, \"\\n\")"
      ],
      "metadata": {
        "id": "iyyLDaBV_ffK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea230fc-ef0a-4548-aad0-159c3bbaac9f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLEANING] Standardisasi Nama Kolom\n",
            "Columns after standardization:\n",
            "['trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat', 'merch_long', 'is_fraud', 'merch_zipcode']\n",
            "------------------------------------------------------------ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 2. DUPLICATE REMOVAL\n",
        "# ---------------------------------------------------------\n",
        "print(\"[CLEANING] Drop Duplicate (trans_num)\")\n",
        "rows_before = len(df)\n",
        "\n",
        "df = df.drop_duplicates(subset=[\"trans_num\"])\n",
        "\n",
        "print(\"Rows before:\", rows_before)\n",
        "print(\"Rows after :\", len(df))\n",
        "print(\"-\" * 60, \"\\n\")"
      ],
      "metadata": {
        "id": "pnIs2E18_g89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca3ca52c-afb9-41e2-ed71-77973772e88e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLEANING] Drop Duplicate (trans_num)\n",
            "Rows before: 1296675\n",
            "Rows after : 1296675\n",
            "------------------------------------------------------------ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 3. DATETIME STANDARDIZATION\n",
        "# ---------------------------------------------------------\n",
        "print(\"[CLEANING] Parsing Datetime Columns\")\n",
        "\n",
        "df[\"trans_date_trans_time\"] = pd.to_datetime(df[\"trans_date_trans_time\"], errors=\"coerce\")\n",
        "df[\"dob\"] = pd.to_datetime(df[\"dob\"], errors=\"coerce\")\n",
        "\n",
        "print(df[[\"trans_date_trans_time\", \"dob\"]].dtypes)\n",
        "print(\"-\" * 60, \"\\n\")"
      ],
      "metadata": {
        "id": "CQKjESki_iYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049b3e78-fb63-432d-9ece-f99c5e45fe1f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLEANING] Parsing Datetime Columns\n",
            "trans_date_trans_time    datetime64[ns]\n",
            "dob                      datetime64[ns]\n",
            "dtype: object\n",
            "------------------------------------------------------------ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 4. MISSING VALUE HANDLING\n",
        "# ---------------------------------------------------------\n",
        "print(\"[CLEANING] Missing Value Handling\")\n",
        "\n",
        "critical_cols = [\"cc_num\", \"amt\", \"category\", \"gender\"]\n",
        "print(\"Missing before:\")\n",
        "print(df[critical_cols].isna().sum())\n",
        "\n",
        "# FIX: hanya drop kolom krusial\n",
        "df = df.dropna(subset=critical_cols)\n",
        "\n",
        "# FIX: kolom non-kritis diisi default\n",
        "df[\"merch_zipcode\"] = df[\"merch_zipcode\"].fillna(-1)\n",
        "\n",
        "print(\"Rows after cleaning:\", len(df))\n",
        "print(\"-\" * 60, \"\\n\")"
      ],
      "metadata": {
        "id": "NWbwkoK3_jwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "079807bc-4b38-43cd-913b-525eabe8c796"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLEANING] Missing Value Handling\n",
            "Missing before:\n",
            "cc_num      0\n",
            "amt         0\n",
            "category    0\n",
            "gender      0\n",
            "dtype: int64\n",
            "Rows after cleaning: 1296675\n",
            "------------------------------------------------------------ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 5. OUTLIER HANDLING (IQR - CAPPING)\n",
        "# ---------------------------------------------------------\n",
        "print(\"[CLEANING] Outlier Handling (IQR - Capping)\")\n",
        "\n",
        "Q1 = df[\"amt\"].quantile(0.25)\n",
        "Q3 = df[\"amt\"].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower = Q1 - 1.5 * IQR\n",
        "upper = Q3 + 1.5 * IQR\n",
        "\n",
        "# FIX: gunakan capping agar sinyal fraud tidak hilang\n",
        "df[\"amt\"] = df[\"amt\"].clip(lower=lower, upper=upper)\n",
        "\n",
        "print(\"Lower bound:\", round(lower, 2))\n",
        "print(\"Upper bound:\", round(upper, 2))\n",
        "print(\"-\" * 60, \"\\n\")"
      ],
      "metadata": {
        "id": "iLF4SuIU_wj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec20a50-a7c8-44f6-f202-2809b091078b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLEANING] Outlier Handling (IQR - Capping)\n",
            "Lower bound: -100.58\n",
            "Upper bound: 193.38\n",
            "------------------------------------------------------------ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 6. FEATURE ENGINEERING\n",
        "# ---------------------------------------------------------\n",
        "print(\"[FEATURE ENGINEERING]\")\n",
        "\n",
        "df[\"year\"] = df[\"trans_date_trans_time\"].dt.year\n",
        "df[\"month\"] = df[\"trans_date_trans_time\"].dt.month\n",
        "df[\"hour\"] = df[\"trans_date_trans_time\"].dt.hour\n",
        "df[\"year_month\"] = df[\"trans_date_trans_time\"].dt.to_period(\"M\").astype(str)\n",
        "\n",
        "df[\"age\"] = (df[\"trans_date_trans_time\"] - df[\"dob\"]).dt.days // 365\n",
        "\n",
        "# FIX: buang age negatif\n",
        "df = df[df[\"age\"] >= 0]\n",
        "\n",
        "df[\"amt_log\"] = np.log1p(df[\"amt\"])\n",
        "\n",
        "print(\"Total columns:\", df.shape[1])\n",
        "print(\"-\" * 60, \"\\n\")"
      ],
      "metadata": {
        "id": "vmurjrIl_xzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc75b20e-c403-4062-d130-f850f8301c8f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FEATURE ENGINEERING]\n",
            "Total columns: 29\n",
            "------------------------------------------------------------ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 7. ENCODING\n",
        "# ---------------------------------------------------------\n",
        "print(\"[ENCODING] Categorical Encoding\")\n",
        "\n",
        "# FIX: aman jika ada nilai selain M/F\n",
        "df[\"gender_encoded\"] = df[\"gender\"].map({\"M\": 0, \"F\": 1}).fillna(-1)\n",
        "\n",
        "df = pd.get_dummies(df, columns=[\"category\"], prefix=\"cat\")\n",
        "\n",
        "print(\"Columns after encoding:\", df.shape[1])\n",
        "print(\"-\" * 60, \"\\n\")"
      ],
      "metadata": {
        "id": "kGAw4kx2_zJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a48be5-3e35-46fa-afe0-e7d34786840e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ENCODING] Categorical Encoding\n",
            "Columns after encoding: 43\n",
            "------------------------------------------------------------ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 8. NORMALIZATION\n",
        "# ---------------------------------------------------------\n",
        "print(\"[NORMALIZATION] Min-Max Scaling\")\n",
        "\n",
        "df[\"amt_norm\"] = (\n",
        "    (df[\"amt\"] - df[\"amt\"].min()) /\n",
        "    (df[\"amt\"].max() - df[\"amt\"].min() + 1e-9)  # FIX: avoid div by zero\n",
        ")\n",
        "\n",
        "df[\"age_norm\"] = (\n",
        "    (df[\"age\"] - df[\"age\"].min()) /\n",
        "    (df[\"age\"].max() - df[\"age\"].min() + 1e-9)\n",
        ")\n",
        "\n",
        "print(df[[\"amt_norm\", \"age_norm\"]].head())\n",
        "print(\"-\" * 60, \"\\n\")"
      ],
      "metadata": {
        "id": "tk71hQO8_0Y9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d18b084-0c72-4094-fb36-4272a4f2ff9b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NORMALIZATION] Min-Max Scaling\n",
            "   amt_norm  age_norm\n",
            "0  0.020637  0.207317\n",
            "1  0.552203  0.329268\n",
            "2  1.000000  0.524390\n",
            "3  0.228720  0.475610\n",
            "4  0.212917  0.231707\n",
            "------------------------------------------------------------ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 9. ENRICHMENT (FRED)\n",
        "# ---------------------------------------------------------\n",
        "print(\"[ENRICHMENT] Join FRED Interest Rate\")\n",
        "\n",
        "df_fred[\"date\"] = pd.to_datetime(df_fred[\"date\"], errors=\"coerce\")\n",
        "df_fred[\"year_month\"] = df_fred[\"date\"].dt.to_period(\"M\").astype(str)\n",
        "df_fred[\"interest_rate\"] = pd.to_numeric(df_fred[\"value\"], errors=\"coerce\")\n",
        "\n",
        "df_fred = df_fred[[\"year_month\", \"interest_rate\"]].dropna()\n",
        "\n",
        "df_final = df.merge(df_fred, on=\"year_month\", how=\"left\")\n",
        "\n",
        "print(df_final[[\"year_month\", \"amt\", \"interest_rate\"]].head())\n",
        "print(\"===== TRANSFORM END =====\\n\")"
      ],
      "metadata": {
        "id": "hpJnjuRo_17D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23570b45-7356-4e99-db0f-77f440182544"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ENRICHMENT] Join FRED Interest Rate\n",
            "  year_month      amt  interest_rate\n",
            "0    2019-01    4.970            2.4\n",
            "1    2019-01  107.230            2.4\n",
            "2    2019-01  193.375            2.4\n",
            "3    2019-01   45.000            2.4\n",
            "4    2019-01   41.960            2.4\n",
            "===== TRANSFORM END =====\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# DATA QUALITY VALIDATION\n",
        "# =========================================================\n",
        "assert df_final[\"trans_num\"].is_unique\n",
        "assert df_final[\"amt\"].notna().all()\n",
        "assert (df_final[\"amt\"] >= 0).all()\n",
        "assert np.issubdtype(df_final[\"interest_rate\"].dtype, np.number)\n",
        "assert df_final[\"year\"].between(2000, 2030).all()\n",
        "assert df_final[\"cc_num\"].notna().all()\n",
        "\n",
        "print(\"✅ DATA QUALITY CHECK PASSED\")"
      ],
      "metadata": {
        "id": "EH71K5uP_4nJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc42f0b-3ae8-4d8c-ea9f-204881a59daf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DATA QUALITY CHECK PASSED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOAD TO GOOGLE DRIVE (CSV)**"
      ],
      "metadata": {
        "id": "UT2gx-9h_-4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# LOAD TO GOOGLE DRIVE (CSV)\n",
        "# =========================================================\n",
        "OUTPUT_DIR = f\"{BASE_DIR}/processed\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "output_csv_path = f\"{OUTPUT_DIR}/credit_card_transactions_cleaned.csv\"\n",
        "\n",
        "df_final.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(\"✅ Data berhasil disimpan ke Google Drive\")\n",
        "print(\"Path:\", output_csv_path)\n",
        "print(\"Rows:\", df_final.shape[0], \"Cols:\", df_final.shape[1])\n"
      ],
      "metadata": {
        "id": "ioMFg2xGyW02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81bcf9d4-dd54-4c8e-e7de-1abecb2e790e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data berhasil disimpan ke Google Drive\n",
            "Path: /content/drive/MyDrive/dataset/bigdata/uas/processed/credit_card_transactions_cleaned.csv\n",
            "Rows: 1296675 Cols: 46\n"
          ]
        }
      ]
    }
  ]
}